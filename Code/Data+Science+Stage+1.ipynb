{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import statistics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm \n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureCheck(list1, list5):\n",
    "    finalRes = []\n",
    "    positive_list = [\"honda\",\"chevrolet\",\"toyota\",\"nissan\",\"jaguar\",\"fiat\",\"ford\",\"chrysler\",\"bmw\",\n",
    "                 \"mercedes\",\"mercedes-benz\",\"kia\",\"hyundai\",\"gm\",\"audi\",\"volkswagen\",\"mazda\", \"lexus\",\"subaru\"]               \n",
    "    \n",
    "    #final_negative_list = negative_list + negative_list1 + negative_list2 + negative_list3 + negative_list4\n",
    "    \n",
    "    for x in range(0,len(list5)):\n",
    "        res = []\n",
    "        # Feature to tell if previous word is the.\n",
    "        if list5[x][0] - 1 >= 0 and list1[list5[x][0] - 1].lower() =='the':\n",
    "            res.append(1)\n",
    "        else:\n",
    "            res.append(0)\n",
    "            \n",
    "        # Feature to tell if previous to previous word is the.\n",
    "        if list5[x][0] - 2 >= 0 and list1[list5[x][0] - 2].lower() =='the':\n",
    "            res.append(1)\n",
    "        else:\n",
    "            res.append(0)        \n",
    "        \n",
    "        #Feature to tell if preious word is year        \n",
    "        if list5[x][0] - 1 >= 0 and len(list1[list5[x][0] - 1]) == 4 and list1[list5[x][0] - 1].isdigit() :\n",
    "            res.append(1)\n",
    "        else:\n",
    "            res.append(0)\n",
    "            \n",
    "        #Feature to tell if next word is year        \n",
    "        if  list5[x][0] + 1 < len(list1) and len(list1[list5[x][0] + 1]) == 4 and list1[list5[x][0] + 1].isdigit():\n",
    "            res.append(1)\n",
    "        else:\n",
    "            res.append(0)            \n",
    "           \n",
    "        #Feature to tell if previous word is the end of sentence\n",
    "        if list5[x][0] -1 >= 0 :\n",
    "            text = list1[list5[x][0]-1]\n",
    "            if(text[-1] == '.'):\n",
    "                res.append(1)\n",
    "            else:\n",
    "                res.append(0)\n",
    "        else :\n",
    "            res.append(0)\n",
    "        \n",
    "        # Add a feature for whitelist\n",
    "        if list5[x][1].lower() in positive_list:\n",
    "            res.append(1)\n",
    "        else:\n",
    "            res.append(0)\n",
    "        \n",
    "        finalRes.append(res)\n",
    "        #Total 6 features (As of now 5, 1 needs to be added - whitelist)\n",
    "    return finalRes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFrame(list1, list2, posFeatList, negFeatList):\n",
    "    newList = []\n",
    "    #labels = ['Word','Feature1','Feature2','Feature3','Feature4', 'Feature5', 'Feature6', 'Class']\n",
    "    \n",
    "    for i in range(0,len(list1)):\n",
    "        newList.append((list1[i][1],posFeatList[i][0],posFeatList[i][1],posFeatList[i][2], posFeatList[i][3],\n",
    "                        posFeatList[i][4],posFeatList[i][5], 1)) \n",
    "    \n",
    "    for i in range(0,len(list2)):\n",
    "        newList.append((list2[i][1],negFeatList[i][0],negFeatList[i][1],negFeatList[i][2],negFeatList[i][3],negFeatList[i][4],\n",
    "                        negFeatList[i][5],0))\n",
    "        \n",
    "    #df = pd.DataFrame.from_records(newList, columns = labels)\n",
    "    \n",
    "    return newList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path =\"C:\\\\Users\\\\Owner\\\\Desktop\\\\2nd Semester\\\\Data Science\\\\Stage 1\\\\Final Documents\\\\DevSet\\\\\"\n",
    "path = \"C:\\\\Users\\\\Aribhit\\\\Downloads\\\\838\\\\Data-Science-Course-Projects-master\\\\Project Stage 1\\\\Text Documents\\\\DevSet\\\\\"\n",
    "#test_files = random.sample(range(1,220), k=110)\n",
    "stupid_words = ['a','an','the','have','has','been','was','is','by','to','at','for','in','of','from','like','with','were',\n",
    "                'are','what','where','how','why','who','it',\"it's\",'and','but','on',\"its\",'we','our','over',\n",
    "               'under',\"about\",\"upon\",\"these\",\"those\",\"this\",\"that\",\"i\",\"they\",\"them\"]\n",
    "bigDataList = []\n",
    "for j in range(1,221):\n",
    "    if True :\n",
    "        fileIndex = str(j).zfill(3)\n",
    "        filePath = path + fileIndex + '.txt'         \n",
    "        F = open(filePath,\"r\") \n",
    "        read_data = F.read()    \n",
    "        examples = read_data.split()\n",
    "        examples = [word.strip(\" .,;:()\") for word in examples]\n",
    "        neg_examples = []\n",
    "        pos_examples = []\n",
    "        \n",
    "        for i,word in enumerate(examples):\n",
    "            word = re.sub(\"\\'s\",\"\",word)\n",
    "            word = re.sub(\"\\’s\",\"\",word) \n",
    "            if 'carMake' in word :\n",
    "                if word.count(\"carMake\") == 2 :\n",
    "                    temp = re.sub('<[^>]*>', '',word)\n",
    "                    pos_examples.append([i,temp])\n",
    "                else :\n",
    "                    temp = word+\" \"+examples[i+1]\n",
    "                    temp = re.sub('<[^>]*>', '',temp)\n",
    "                    pos_examples.append([i,temp])\n",
    "                    examples[i+1] = \"__\"\n",
    "            else : #word[0].isupper() and\n",
    "                if word[0].isupper() and word.lower() not in stupid_words and not (any(ch.isdigit() for ch in word)) :\n",
    "                    neg_examples.append([i,word])\n",
    "                    temp2 = examples[i+1] if i<len(examples)-1 else \"__\"\n",
    "                    if temp2.lower() not in stupid_words and 'carMake' not in temp2 and not (any(ch.isdigit() for ch in temp2)):\n",
    "                        if random.random() <1:\n",
    "                            neg_examples.append([i,word+\" \"+temp2])              \n",
    "        featureList1 = featureCheck(examples, pos_examples)\n",
    "        featureList2 = featureCheck(examples, neg_examples)\n",
    "        fileList = createFrame(pos_examples,neg_examples,featureList1,featureList2)\n",
    "        bigDataList.extend(fileList)\n",
    "        F.close()\n",
    "labels = ['Word','F1','F2','F3','F4','F5','F6','Class']\n",
    "df = pd.DataFrame.from_records(bigDataList, columns = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.columns[1:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.884310136502\n"
     ]
    }
   ],
   "source": [
    "clf_m1 = RandomForestClassifier(n_jobs=2, random_state=0)\n",
    "scores_m1 = cross_val_score(clf_m1, df[features], df['Class'], cv=10, scoring = 'roc_auc')\n",
    "print(sum(scores_m1) / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.849132595747\n"
     ]
    }
   ],
   "source": [
    "clf_m2 = svm.SVC(kernel='linear', C=1)\n",
    "scores_m2 = cross_val_score(clf_m2, df[features], df['Class'], cv=10, scoring = 'roc_auc')\n",
    "print(sum(scores_m2) / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.884928325159\n"
     ]
    }
   ],
   "source": [
    "clf_m3 = LogisticRegression()\n",
    "scores_m3 = cross_val_score(clf_m3, df[features], df['Class'], cv=10, scoring = 'roc_auc')\n",
    "print(sum(scores_m3) / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.885786301852\n"
     ]
    }
   ],
   "source": [
    "clf_m5 = LinearRegression()\n",
    "scores_m5 = cross_val_score(clf_m5, df[features], df['Class'], cv=10, scoring = 'roc_auc')\n",
    "print(sum(scores_m5) / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.884690343284\n"
     ]
    }
   ],
   "source": [
    "clf_m4 = DecisionTreeClassifier()\n",
    "scores_m4 = cross_val_score(clf_m4, df[features], df['Class'], cv=10, scoring = 'roc_auc')\n",
    "print(sum(scores_m4) / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3152\n",
       "1     829\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_train'] = np.random.uniform(0,1,len(df)) <= 0.8\n",
    "df.head\n",
    "train, test = df[df['is_train']==True], df[df['is_train']==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(class_weight = 'balanced')\n",
    "\n",
    "clf.fit(train[features], train['Class'])\n",
    "preds = clf.predict(test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95967741935483875"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.precision_score(test['Class'],preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70833333333333337"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.recall_score(test['Class'],preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81506849315068497"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.f1_score(test['Class'],preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path =\"C:\\\\Users\\\\Owner\\\\Desktop\\\\2nd Semester\\\\Data Science\\\\Stage 1\\\\Final Documents\\\\TestSet\\\\\"\n",
    "path = \"C:\\\\Users\\\\Aribhit\\\\Downloads\\\\838\\\\Data-Science-Course-Projects-master\\\\Project Stage 1\\\\Text Documents\\\\TestSet\\\\\"\n",
    "#test_files = random.sample(range(1,220), k=110)\n",
    "stupid_words = ['a','an','the','have','has','been','was','is','by','to','at','for','in','of','from','like','with','were',\n",
    "                'are','what','where','how','why','who','it',\"it's\",'and','but','on',\"its\",'we','our','over',\n",
    "               'under',\"about\",\"upon\",\"these\",\"those\",\"this\",\"that\",\"i\",\"they\",\"them\"]\n",
    "testDataList = []\n",
    "for j in range(1,111):\n",
    "    if True :\n",
    "        fileIndex = str(j).zfill(3)\n",
    "        filePath = path + fileIndex + '.txt'         \n",
    "        F = open(filePath,\"r\") \n",
    "        read_data = F.read()    \n",
    "        examples = read_data.split()\n",
    "        examples = [word.strip(\" .,;:()\") for word in examples]\n",
    "        neg_examples = []\n",
    "        pos_examples = []\n",
    "        \n",
    "        for i,word in enumerate(examples):\n",
    "            word = re.sub(\"\\'s\",\"\",word)\n",
    "            word = re.sub(\"\\’s\",\"\",word) \n",
    "            if 'carMake' in word :\n",
    "                if word.count(\"carMake\") == 2 :\n",
    "                    temp = re.sub('<[^>]*>', '',word)\n",
    "                    pos_examples.append([i,temp])\n",
    "                else :\n",
    "                    temp = word+\" \"+examples[i+1]\n",
    "                    temp = re.sub('<[^>]*>', '',temp)\n",
    "                    pos_examples.append([i,temp])\n",
    "                    examples[i+1] = \"__\"\n",
    "            else : #word[0].isupper() and\n",
    "                if word[0].isupper() and word.lower() not in stupid_words and not (any(ch.isdigit() for ch in word)) :\n",
    "                    neg_examples.append([i,word])\n",
    "                    temp2 = examples[i+1] if i<len(examples)-1 else \"__\"\n",
    "                    if temp2.lower() not in stupid_words and 'carMake' not in temp2 and not (any(ch.isdigit() for ch in temp2)):\n",
    "                        if random.random() <1:\n",
    "                            neg_examples.append([i,word+\" \"+temp2])              \n",
    "        featureList1 = featureCheck(examples, pos_examples)\n",
    "        featureList2 = featureCheck(examples, neg_examples)\n",
    "        fileList = createFrame(pos_examples,neg_examples,featureList1,featureList2)\n",
    "        testDataList.extend(fileList)\n",
    "        F.close()\n",
    "labels = ['Word','F1','F2','F3','F4','F5','F6','Class']\n",
    "test_df = pd.DataFrame.from_records(testDataList, columns = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1459\n",
       "1     406\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds2 = clf.predict(test_df[features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95501730103806226"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.precision_score(test_df['Class'],preds2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67980295566502458"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.recall_score(test_df['Class'],preds2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79424460431654675"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.f1_score(test_df['Class'],preds2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
